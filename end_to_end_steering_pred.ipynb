{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already preprocessed\n",
      "Total Processing tim : 0.0003337860107421875s\n"
     ]
    }
   ],
   "source": [
    "\"\"\"DATA PREPROCESSING\"\"\"\n",
    "\n",
    "from PIL import Image, ImageFilter, ImageEnhance, ImageFile\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "import shutil\n",
    "\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "def crop(img):\n",
    "    width, height = img.size\n",
    "    img = img.crop((0, 120, width, height))\n",
    "    return img\n",
    "\n",
    "\n",
    "def blur(img):\n",
    "    img = img.filter(ImageFilter.BLUR)\n",
    "    return img\n",
    "\n",
    "def darken(img):\n",
    "    enhancer = ImageEnhance.Brightness(img)\n",
    "    img = enhancer.enhance(0.5) # value proportional to brightness\n",
    "    return img\n",
    "\n",
    "def preprocess(data_path, save_dir):\n",
    "    start = time.time()\n",
    "    if not save_dir.exists():\n",
    "        save_dir.mkdir(parents=True, exist_ok=True)\n",
    "        print(\"Save Dir created\")\n",
    "    \n",
    "\n",
    "        for file in data_path.iterdir():\n",
    "            if str(file.suffix) == \".jpg\":\n",
    "                img = Image.open(data_path/file)\n",
    "                img = crop(img)\n",
    "                img = blur(img)\n",
    "                img = darken(img)\n",
    "\n",
    "                print(f\"Saving : {save_dir/file.name}\")\n",
    "                img.save(save_dir/file.name)\n",
    "\n",
    "            if str(file.stem)==\"data\":\n",
    "                shutil.copy(str(file),str(save_dir/file.name) )\n",
    "\n",
    "    else:\n",
    "        print(\"Already preprocessed\")\n",
    "\n",
    "    end = time.time()\n",
    "\n",
    "    print(f\"Total Processing tim : {end-start}s\")\n",
    "            \n",
    "\n",
    "def vis_image(img):\n",
    "    # plt.imshow(np.transpose(img,  (1, 2, 0)))\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "try:\n",
    "    from google.colab import drive\n",
    "    drive.mount(\"/content/drive\")\n",
    "\n",
    "    root_dir = Path(\"/content/drive/MyDrive/research\")\n",
    "    data_path = root_dir/\"driving_dataset\"\n",
    "    save_dir = root_dir/\"driving_dataset_preprocessed\"\n",
    "except:\n",
    "    root_dir=Path(\"/home/avishkar/Desktop/research\")\n",
    "    data_path=root_dir/\"driving_dataset\"\n",
    "    save_dir=root_dir/\"driving_dataset_preprocessed\"\n",
    "\n",
    "preprocess(data_path=data_path, save_dir=save_dir)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: imageio in /home/avishkar/.local/lib/python3.10/site-packages (2.34.1)\n",
      "Requirement already satisfied: pillow>=8.3.2 in /home/avishkar/.local/lib/python3.10/site-packages (from imageio) (10.3.0)\n",
      "Requirement already satisfied: numpy in /home/avishkar/.local/lib/python3.10/site-packages (from imageio) (1.26.3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_27617/3186932329.py:36: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
      "  img = iio.imread(self.data_dir/img_path)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaAAAAGzCAYAAABpdMNsAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy80BEi2AAAACXBIWXMAAA9hAAAPYQGoP6dpAABDD0lEQVR4nO3deXiU1dk/8O/MJDNJJhsBskFAQGUVrAgYsSBCgfjWQoEK2hZQihu4oYL0p7KoDYJ1B5TXFtQCUqxgtRWrCFgVqKCIS6WCWKAQQCQLWWa9f3/4MmVMAucOGU4C3w/XXBeZOXPmPNvc88zzzPdxiIiAiIjoFHPaHgAREZ2ZWICIiMgKFiAiIrKCBYiIiKxgASIiIitYgIiIyAoWICIisoIFiIiIrGABIiIiK1iAzmCzZ89Ghw4dEA6HbQ+l0Zk+fTocDoftYZy2Lr30UnTp0qXOzw8Gg5g8eTLy8vLgdDoxdOhQAIDD4cD06dPrZ5ANwKhRo3DllVfaHkadsQCdwPvvv4/p06ejuLjY9lDqVWlpKR566CFMmTIFTud/V4Pbb78dF1xwATIyMpCUlISOHTti+vTpOHLkiFG/JSUlmDx5Ms455xwkJiaidevWGDduHHbt2hXVbsWKFRg0aBByc3Ph8XjQsmVLjBgxAp9++mmN/f75z3/GBRdcgISEBLRq1QrTpk1DMBis1q64uBjXXXcdmjdvDq/Xi379+uHDDz9UzJm6+81vfoOVK1eekteKtcY+Lb///e8xZ84cjBgxAs899xxuv/32U/K6e/fuxfTp07Fly5Za2yxbtgz5+fnwer1IT0/HxRdfjLfffrvW9u+++y4cDgccDge++eabqMemTJmCP/3pT/j444/raxJOLaHjmjNnjgCQnTt32h5KvXr00UclNTVVKisro+7v3bu33HLLLfLEE0/IggUL5MYbbxSPxyO9e/eWUCh03D5DoZD06NFDvF6v3HXXXfK///u/MmXKFElJSZEWLVpIaWlppO2MGTNk5MiRMmvWLHn22WflgQcekLZt20piYqJs2bIlqt+//vWv4nA4pF+/frJgwQK5+eabxel0yg033FDt9S+++GLxer0yffp0eeqpp6RTp06SkpIi//rXv05yjkWbNm2afH/z8Xq9MmbMmHp9HVtsT0vfvn2lc+fOdX7+yJEjpUWLFtXuByDTpk07iZEd3wcffCAAZOHChTU+Pm3aNHE4HPKzn/1Mnn76aXnyySfl+uuvl+eff77G9qFQSM4//3zxer0CQA4ePFitTc+ePeWXv/xlfU7GKcMCdAKnUwE6cuRI5P9du3aVX/ziF0bPe/jhhwWArF+//rjt3nvvPQEgTz31VNT9v//97wWAvPzyy8d9flFRkcTFxcn1118fdX+nTp2kW7duEggEIvf9v//3/8ThcMg///nPyH3Lli0TALJ8+fLIfQcOHJD09HS56qqrTjidGixAeseufydysgWoX79+NT7fZgFav369OBwOeeSRR4z7mz9/vjRt2lRuvfXWWgvQww8/LF6vV8rKyk5m6FbwK7jjmD59Ou666y4AQJs2bSK7wV9//XWkzR/+8Ad0794diYmJyMjIwKhRo7B79+6ofo5+n/3555+jX79+SEpKQosWLTB79uxqr/nkk0+ic+fOSEpKQpMmTXDhhRdiyZIlUW0++ugjFBQUIDU1FcnJyejfvz82bNgQ1WbRokVwOBxYt24dbrrpJmRmZqJly5YAgJ07d2Lr1q0YMGCA0Xw466yzAOCEX0OWlpYCALKysqLuz8nJAQAkJiYe9/mZmZlISkqKep3PP/8cn3/+Oa677jrExcVF7r/pppsgInjppZci97300kvIysrCsGHDIvc1b94cV155JV555RX4fL7jvn5t3n33XfTo0QMJCQlo164dnnnmmWptHA4HysvL8dxzz0XWk7Fjx2LNmjVwOBxYsWJFtecsWbIEDocD69evBwCMHTsWycnJ+OqrrzBo0CB4vV7k5uZi5syZkO+F1ofDYTz22GPo3LkzEhISkJWVheuvvx6HDx+u0zSaTMtRJ7v+AcDrr7+Ovn37IiUlBampqejRo0e19RyA0TZzrK+//hoOhwNr1qzBZ599Fhn/2rVra32OyfR8++23uPPOO3HeeechOTkZqampKCgoiPrqa+3atejRowcA4Jprrom89qJFiwAAjz32GLKzs3HrrbdCRE74tfa3336Le+65BzNnzkR6enqt7X70ox+hvLwcb7755nH7a5AsF8AG7eOPP5arrrpKAMijjz4qL7zwgrzwwguRT3IPPPCAOBwOGTlypMybN09mzJghzZo1k7POOksOHz4c6adv376Sm5sreXl5cuutt8q8efPksssuEwDy17/+NdJuwYIFAkBGjBghzzzzjDz++OMybtw4ueWWWyJtPv30U/F6vZKTkyP333+/zJo1S9q0aSMej0c2bNgQabdw4UIBIJ06dZK+ffvKk08+KbNmzRIRkT/84Q8CQLZu3VrjdAcCATl48KD85z//kTfeeEM6dOggKSkpcujQoePOr4MHD4rX65UOHTrI6tWrZc+ePbJ27Vo577zzpEePHlF7MEcdPnxYDhw4IFu3bpVrr71WAMiCBQsijx8d68aNG6s9t2XLljJs2LDI32effbYUFBRUa/fss88ed3qPZ+vWrZKYmCitWrWSwsJCuf/++yUrK0u6du0atQf0wgsviMfjkR/+8IeR9eT999+XcDgseXl5Mnz48Gp9X3755dKuXbvI32PGjJGEhAQ555xz5Je//KU89dRT8uMf/1gAyL333hv13F/96lcSFxcn48ePl6efflqmTJkiXq9XevToIX6/P9KurKxMDh48eMJbcXHxCadFpH7Wv4ULF4rD4ZAuXbrIgw8+KHPnzpVf/epXUV8jmW4z33fkyBF54YUXpEOHDtKyZcvI+IuKikSk+h6Q6fR88MEH0q5dO7n77rvlmWeekZkzZ0qLFi0kLS1N/vOf/4jId3vwM2fOFABy3XXXRV57x44dIiLSrFkz+clPfiKPPvqoNG3aVABIdna2PPnkkzVOy0033SSdO3eWYDAY2eOuaQ8oEAhIYmKi3HHHHbXOl4aKBegEavsK7uuvvxaXyyUPPvhg1P2ffPKJxMXFRd3ft29fARD1Pa/P55Ps7OyoN6YhQ4ac8GuHoUOHitvtjqzUIiJ79+6VlJQU6dOnT+S+o28Al1xyiQSDwag+7rnnHgFQ6y77+vXrBUDk1r59e1mzZs1xx3XUa6+9Jjk5OVHPHzRoUK2v1b59+0i75ORkueeee6KONR2d/7t27ar23B49eshFF10U+dvr9cq1115brd1f/vIXASCrVq0ymoZjDR06VBISEuTf//535L7PP/9cXC6X8VdwU6dOFY/HE/Umf+DAAYmLi4t6MxwzZowAkJtvvjlyXzgclv/5n/8Rt9sdefP5+9//LgBk8eLFUa+zatWqavcf7fNEt759+xpNy8muf8XFxZKSkiK9evWqdvwxHA5H/m+6zdSmtq/wvl+ATKenqqqq2jHQnTt3isfjkZkzZ0buq+0ruG+//VYASNOmTSU5OVnmzJkjy5Ytk8GDBwsAefrpp6Paf/zxx+JyueSNN94QETluARIROffcc2v88NXQ8Su4Onr55ZcRDodx5ZVX4ptvvoncsrOzcc4552DNmjVR7ZOTk/GLX/wi8rfb7UbPnj3x1VdfRe5LT0/Hnj178MEHH9T4mqFQCH/7298wdOhQtG3bNnJ/Tk4Orr76arz77ruRr8GOGj9+PFwuV9R9hw4dQlxcHJKTk2t8nU6dOuHNN9/EypUrMXnyZHi9XuOz4Jo3b44f/OAHePDBB7Fy5UpMnz4df//733HNNdfU2H7hwoVYtWoV5s2bh44dO6KyshKhUCjyeGVlJQDA4/FUe25CQkLk8aNta2t3bF+mQqEQ3njjDQwdOhStWrWK3N+xY0cMGjTIuJ/Ro0fD5/NFfV24bNkyBIPBqHXiqIkTJ0b+73A4MHHiRPj9frz11lsAgOXLlyMtLQ0/+tGPota97t27Izk5OWrdmzx5Mt58880T3n77298azY+TXf/efPNNlJWV4e67744sl2On9Vgm28zJ0EyPx+OJnC0aCoVw6NAhJCcno3379kZnWR7dfg4dOoRnn30Wd955J6688kr85S9/QadOnfDAAw9Etb/llltQUFCAgQMHGk1LkyZNqp0h1xjEnbgJ1eTLL7+EiOCcc86p8fH4+Piov1u2bFltA2vSpAm2bt0a+XvKlCl466230LNnT5x99tkYOHAgrr76avTu3RsAcPDgQVRUVKB9+/bVXq9jx44Ih8PYvXs3OnfuHLm/TZs26mlLTU2NHB8aMmQIlixZgiFDhuDDDz9Et27dan3eV199hX79+uH555/H8OHDI88/66yzMHbsWLz++usoKCiIek5+fn7k/6NGjULHjh0BAA8//DCA/x43qun4TVVVVdRxpcTExFrbHduXqYMHD6KysrLGZdy+fXv89a9/NeqnQ4cO6NGjBxYvXoxx48YBABYvXoyLLroIZ599dlRbp9MZ9WYIAOeeey4ARI49fvnllygpKUFmZmaNr3fgwIHI/zt16oROnToZjfNE6mP927FjBwAY/cbHZJs5GZrpCYfDePzxxzFv3jzs3Lkz6kNS06ZNT/haR9e9+Ph4jBgxInK/0+nEyJEjMW3aNOzatQutWrXCsmXL8P7779f6k4SaiEij/F0aC1AdhcNhOBwOvP7669X2MABU27uoqQ2AqIPLHTt2xLZt2/Daa69h1apV+NOf/oR58+bhvvvuw4wZM+o0zpredJs2bYpgMIiysjKkpKScsI9hw4bhl7/8JV588cXjFqBFixahqqoKP/7xj6Pu/8lPfgIAeO+996oVoGM1adIEl112GRYvXhwpQEdPYNi3bx/y8vKi2u/btw89e/aM/J2Tk4N9+/ZV6/fofbm5ucebzJgaPXo0br31VuzZswc+nw8bNmzAU089Vae+wuEwMjMzsXjx4hofb968eeT/JSUlRnt+brcbGRkZdRrP8WiL/rFMtplT5Te/+Q3uvfdeXHvttbj//vuRkZEBp9OJ2267zeiH3BkZGUhISEB6enq16Tr6QeLw4cNo1aoV7rrrLvzsZz+D2+2OfOg4emLO7t274ff7q63Lhw8frvXDcEPGAnQCtX2qaNeuHUQEbdq0iXxCrQ9erxcjR47EyJEj4ff7MWzYMDz44IOYOnUqmjdvjqSkJGzbtq3a87744gs4nc5qb9I16dChA4Dvzobr2rXrCdv7fD6Ew2GUlJQct93+/fshIlGfDgEgEAgAQI0/HP2+ysrKqNc5//zzAQCbNm2KKjZ79+7Fnj17cN1110W1/fvf/45wOBz149qNGzciKSlJvZyaN2+OxMREfPnll9Ueq2kZHO8T6KhRozBp0iQsXboUlZWViI+Px8iRI6u1C4fD+Oqrr6LG+q9//QvAf89GbNeuHd566y307t37hG/wt956K5577rnjtgGAvn37Rp0pVtO01Mf6165dOwDAp59+Wm3v71TTTM9LL72Efv364Xe/+11Uu+LiYjRr1izyd23rgNPpxPnnn48PPvgAfr8fbrc78tjevXsj4wG+KzJLliyp8azACy64AN26dYv6oWswGMTu3bsjH/QaEx4DOgGv1wug+inIw4YNg8vlwowZM6p9IhMRHDp0SP1a33+O2+1Gp06dICIIBAJwuVwYOHAgXnnllahTwffv348lS5bgkksuQWpq6glf5+jXXps2bYq6v7i4OFIsjvXss88CAC688MLIfRUVFfjiiy+ivnc+99xzISL44x//GPX8pUuXAgB+8IMfRO479muio77++musXr066nU6d+6MDh06YMGCBVGFbf78+XA4HFFfZ4wYMQL79+/Hyy+/HLnvm2++wfLly3HFFVfUeHzoeFwuFwYNGoSVK1dGJTn885//xBtvvFGtvdfrrfVU9WbNmqGgoAB/+MMfsHjxYgwePDjqjetYx+4ZiQieeuopxMfHo3///gCAK6+8EqFQCPfff3+15waDwagx1PUYUE3TUh/r38CBA5GSkoLCwsLIV6PHTmtdfPHFF9WSNkxopsflclUb3/Lly/Gf//wn6r7a3i8AYOTIkQiFQlEfCKqqqrB48WJ06tQpslezYsWKarejH1aef/55PProo1H9fv7556iqqsLFF1+sngfWWTn1oRH5xz/+IQDk8ssvl+eff16WLl0aOQ27sLBQAMjFF18ss2fPlvnz58vkyZPlnHPOkTlz5kT6qO2MnDFjxkjr1q0jf19wwQVy+eWXy4MPPijPPvus3HHHHeLxeOSKK66ItDl62miLFi3kwQcflIceekjatm1b62mwH3zwQY3T1aVLl2o/zlyxYoXk5eXJ7bffLvPmzZPHHntMhg8fLg6HQy688ELx+XyRtmvWrKl2RtE333wj2dnZ4na75ZZbbpFnnnlGrr/+enG5XNK5c+eo52dmZspVV10lDz30kCxYsEDuuusuycjIkISEBHnvvfeixvXqq6+Kw+GQyy67TBYsWCC33HKLOJ1OGT9+fFS7YDAoF110kSQnJ8uMGTNk7ty50rlzZ0lJSZEvvvii2ryHwQ+MP/74Y0lISJBWrVrJrFmz5IEHHqjxNGyR706r9nq98tvf/laWLl0atTxERF566aXIWWfLli2r9lrHnoY9evRomTt3buQ07F//+tdRba+//noBIAUFBfLoo4/KU089Jbfeeqvk5uZG/RC3rmqblvpY/46eFt+lSxf5zW9+I/Pnz5cbbrhBRo8eHWljus2ISI1n8ZmeBWc6Pffdd58AkLFjx0bSODIyMqRt27ZRr+33+yU9PV3at28vzz77rCxdulS++uorERGpqKiQzp07S3x8vNx5553yxBNPSI8ePcTlch331HKR458F9/DDD0tSUlJU0khjwQJk4P7775cWLVqI0+ms9qb1pz/9SS655BLxer2R38BMmDBBtm3bFmljujE988wz0qdPH2natKl4PB5p166d3HXXXVJSUhL1vA8//FAGDRokycnJkpSUJP369Yv8TuOoExWgRx55RJKTk6WioiJy3/bt22X06NGRSJyEhATp3LmzTJs2rdqv2GsqQCIie/bskWuvvVbatGkjbrdbcnJyZPz48dU2nGnTpsmFF14oTZo0kbi4OMnNzZVRo0bV+ludFStWyPnnny8ej0datmwp99xzT9TvXY769ttvZdy4cdK0aVNJSkqSvn371jgPhg8fLomJiVG/16rNunXrpHv37uJ2u6Vt27by9NNP15iE8MUXX0ifPn0kMTFRAFQ7jdnn80mTJk0kLS2t2inIIt+tD16vV3bs2CEDBw6UpKQkycrKkmnTptUYg7RgwQLp3r27JCYmSkpKipx33nkyefJk2bt37wmn6USONy31sf79+c9/losvvlgSExMlNTVVevbsKUuXLo08fqoKkOn0VFVVyR133CE5OTmSmJgovXv3lvXr10vfvn2rvfYrr7winTp1kri4uGqnZO/fv1/GjBkjGRkZ4vF4pFevXkY/DzheAerVq5dxqklD4xCxcESPrCspKUHbtm0xe/bsyJlZZ5KsrCyMHj0ac+bMOWWvGQwGkZubiyuuuKLasQTguySEl156yfiUd6ItW7bgggsuwIcffhg5XtqY8BjQGSotLQ2TJ0/GnDlzzrjLMXz22WeorKzElClTTunrrly5EgcPHsTo0aNP6evS6WvWrFkYMWJEoyw+AMA9IKIY27hxI7Zu3Yr7778fzZo1q/WHi9wDojMN94CIYmz+/Pm48cYbkZmZieeff972cIgaDO4BERGRFdwDIiIiK1iAiIjIigYXxRMOh7F3716kpKQ0ynA9IqIznYigrKwMubm5UbFY39fgCtDevXuN8syIiKhh2717d9SVcL+vwRWgo+nMffr2jroE8/GUl5ufthr0+1XjiaslkbcmYdH1HQ6HTtzo/1RU6n6r41J8uZqQoPsmNmQQKnosf9B8OhPd5vMbAIIh83No4pRfOHsTzJOc27XIUfW97xvdpbObHueSzN+3a+9BVd97vzl+yOyxHE7d8klJTjJu61IuoDSP+fZWFUw4caNjxCfocgN9AfPts6Kqet7icYXNtze/v+rEjY4R54w/caP/41Qsn1AohE8+/eKEafsxK0Bz587FnDlzUFRUhG7duuHJJ5+MSjOuzdGv3eLi4owLUFyc+UYhId0GpOk7LLq+FfUHLpfu60hNAYrTNAYA5YmTLkV7TcEHAIH5hh/n1M1DzbJ3x+s2pXjDdbsu/WvGDQCu43xF8n0O5bpS2yUVahKnLECa6YyDdrvXLZ+QmK+HLpfyh98O8+1HM78BwKX4QOHUvk/g+AnxQIxOQli2bBkmTZqEadOmRS5iNmjQoBoTkImI6MwUkwL0yCOPYPz48bjmmmvQqVMnPP3000hKSsLvf//7am19Ph9KS0ujbkREdPqr9wLk9/uxefPmyCWdge8uxjRgwACsX7++WvvCwkKkpaVFbjwBgYjozFDvBeibb75BKBRCVlZW1P1ZWVkoKiqq1n7q1KkoKSmJ3Hbv3l3fQyIiogbI+llwHo9HfaVKIiJq/Op9D6hZs2ZwuVzYv39/1P379+9HdnZ2fb8cERE1UvVegNxuN7p3747Vq1dH7guHw1i9ejXy8/Pr++WIiKiRislXcJMmTcKYMWNw4YUXomfPnnjsscdQXl6Oa665JhYvR0REjVBMCtDIkSNx8OBB3HfffSgqKsL555+PVatWVTsx4Xj8Pj/CIbMfbIVC5r/oDAQUv/6E7gedoZAuIUATdedU/BgNgPG8A4CQIk0AAFzKHzo6FMkJ2quDhMLm7bXJgkeOlBu3LS0zbwsAyd5UVfuAYjoTFekDAJDiN58zDofuS5NwyDytIBjQbT+lYj6WOKeu71BIl1bgcCi2CeW2HFL8Yr3Kp0tjkbB5+6Qk8zQJ0/fkmJ2EMHHiREycODFW3RMRUSPHyzEQEZEVLEBERGQFCxAREVnBAkRERFawABERkRUsQEREZAULEBERWcECREREVrAAERGRFdYvx1Abv9+PcNgsTsbvN4+TENFF8WjidYLKKJ44l3kESnyc7rNCZVXs4oniRLfaCMyjR7RRPA7FZ6igtm8xjzMqrahS9e1NSVa19/vNo2HCys+VLo/XuK12+UDMx+1w6SKegoosK0dYF60TDuiWpzjiNa1VfQcU7yt+5bas2TY9iu0hZNiWe0BERGQFCxAREVnBAkRERFawABERkRUsQEREZAULEBERWcECREREVrAAERGRFSxARERkBQsQERFZwQJERERWNNgsuO8y2MxyioJB85wnd7x5fhQABEPmOXOBgHlWEgC4XOaz36XIjQMAhyInKxjSjTtOF9kFB8zHEg7rcrI0YxfdLIRHkb8XdupmSmVQl9mlyYKr8umWZ6I33bitU7keVhX7jNsGoMtSDIfM52FI8R4BAG5tnl68+fIPK/MoqxRZl35lHqXLaT6dIcW2ZtqWe0BERGQFCxAREVnBAkRERFawABERkRUsQEREZAULEBERWcECREREVrAAERGRFSxARERkBQsQERFZ0WCjeCCAwzSVxaGJn9BOsnnEhhhGBx2licvRxNkAQLwiRiYY0o1bdEkviFfE1LiVOT9BRfRIvFu37FOSk43buj2Jqr6rwrqZeKTSfDqDfvP4GwBonpli3NabkKDq+5uqI8ZtK3xlqr6P+KuM2zqVOUxhl249jFfEavmqKlV9V1Qo2iujrDTvQQG/+ToYNly/uQdERERWsAAREZEVLEBERGQFCxAREVnBAkRERFawABERkRUsQEREZAULEBERWcECREREVrAAERGRFSxARERkRcPNgnP8382EIv9IGXumymBLjHer+k5W5GolJ3lVffsD5rlNFVXmmVoAEA7pcsySk8ynM1GZqeYLmC/QykBA1bdLsTxLy/2qvsurQqr2/oB5//Eu3Uq+7z+7jdsmJSap+nYqVpXU5FRV325XvHHb8soKVd8B3eIBFMsz6Nethx7FdAagycUENPGVwaD5uJkFR0REDVq9F6Dp06fD4XBE3Tp06FDfL0NERI1cTL6C69y5M956663/vkhcw/2mj4iI7IhJZYiLi0N2dnYsuiYiotNETI4Bffnll8jNzUXbtm3x85//HLt27aq1rc/nQ2lpadSNiIhOf/VegHr16oVFixZh1apVmD9/Pnbu3Ikf/vCHKCur+WqHhYWFSEtLi9zy8vLqe0hERNQAOUREeWKyTnFxMVq3bo1HHnkE48aNq/a4z+eDz/ffSwiXlpYiLy8P3bt3Q5zhZXErq0qMx+OKNz+lEQAcilO8XcrLZqck8zTs72tIp2G73eanYQeU5+02pNOwwy7zU6vVp2GHzOd5gke3/VRVml+qWnsatnIVR3y8+dGMw8Xm71cA4Fecth1QXKIeAJyK9yyn07xtOBzG7t17UVJSgtTU2k+vj/nZAenp6Tj33HOxffv2Gh/3eDzweDyxHgYRETUwMf8d0JEjR7Bjxw7k5OTE+qWIiKgRqfcCdOedd2LdunX4+uuv8f777+OnP/0pXC4Xrrrqqvp+KSIiasTq/Su4PXv24KqrrsKhQ4fQvHlzXHLJJdiwYQOaN2+u6scJJ5wOs/qo+R4z3qWruUle82MSaYpjHQCQnpZs3DbRo/vu3aH4vtbn18bI6L5nFsX36eGw7jhAOGw+lirlcZeSYvPjBpWVuuNooaDuOI1X8S11KGx27PSoon3mUTzxyq/LW+TkGrdNdOrejpqkpxm3TU9LUfVdVmF+fAkAKo85jn0iHsWxRQBwKyKhfIpjhXqKyDPDg2j1XoBefPHF+u6SiIhOQ8yCIyIiK1iAiIjIChYgIiKyggWIiIisYAEiIiIrWICIiMgKFiAiIrKCBYiIiKxgASIiIitYgIiIyIqYX46hrlKTExAXZza8jFTzyUhM1GVZeZPM89q8CbprDcXFaeq/Lt8rpIg9C4tuNfBrOgdQ5TPPawvqukZ5hXkGV2WV7npAmmv8hJWf5by62ECkJpgv/8NHdNPpdJqP3aVoC8B4GwaAsPJ6Wr6g+XQmKvPXspo1UbUPKi6rVubVXdvrm2+Ljdv6g7qcRpciG9OtuOZRyPA9gntARERkBQsQERFZwQJERERWsAAREZEVLEBERGQFCxAREVnBAkRERFawABERkRUsQEREZAULEBERWdFgo3iymqfDHW8WbeN2hY37dTl1kTaaGu1QxpQExTx6pEIRZwMAZUf8xm0rlX0HQubzGwD8fvPIlMpK82gdAKiqMp/OsOjGDfN0FSSoYpWAZqm62BlF4hDg0m3WSUlJxm010ToAEA6Zr1uBoG7bDMJ8eVZWlqv6TknWZSUlJphHfGWkp6r6TlD07f72sKpvv998+wn4zNs6DKOJuAdERERWsAAREZEVLEBERGQFCxAREVnBAkRERFawABERkRUsQEREZAULEBERWcECREREVrAAERGRFSxARERkRYPNgotzfnczIQ7zXK1gSDcOvyL3LODTde4PmPddXqnLa9OM2xFWhJ4BqKzS5bWVV1QYtw0GdNMJmC97Mcyn+m978+WZ5lV1jZB5PB4A4ECJ+XwJhXTTCcV8CQZ1eXrfHi4xbuv16mZiMGg+E50u3WftKr9uHU9LTTFum5yoy5lLcJtlYgJAy6ymqr5DYfPtxxcwn9+BQBCffLbthO24B0RERFawABERkRUsQEREZAULEBERWcECREREVrAAERGRFSxARERkBQsQERFZwQJERERWsAAREZEVLEBERGRFg82CC4YdcBrmFDkUWVY+RUYaAJRXmWdw+fy6vjWRXSFlhl0waD7uyopKVd8VlVWq9qKc56q+RdG3MgvOHWfed3KceaYWAOw+pMu88wXMxx5WZvs5FfNFOQsRCJqvWw6XeeYZAPgV2WQOp275eNy69lJyxLitdvl43OZv0/FxLlXfbtPATQCuOI9x24Bhv9wDIiIiK9QF6J133sEVV1yB3NxcOBwOrFy5MupxEcF9992HnJwcJCYmYsCAAfjyyy/ra7xERHSaUBeg8vJydOvWDXPnzq3x8dmzZ+OJJ57A008/jY0bN8Lr9WLQoEGoqtJ9bUNERKc39TGggoICFBQU1PiYiOCxxx7DPffcgyFDhgAAnn/+eWRlZWHlypUYNWrUyY2WiIhOG/V6DGjnzp0oKirCgAEDIvelpaWhV69eWL9+fY3P8fl8KC0tjboREdHpr14LUFFREQAgKysr6v6srKzIY99XWFiItLS0yC0vL68+h0RERA2U9bPgpk6dipKSksht9+7dtodERESnQL0WoOzsbADA/v37o+7fv39/5LHv83g8SE1NjboREdHpr14LUJs2bZCdnY3Vq1dH7istLcXGjRuRn59fny9FRESNnPosuCNHjmD79u2Rv3fu3IktW7YgIyMDrVq1wm233YYHHngA55xzDtq0aYN7770Xubm5GDp0aH2Om4iIGjl1Adq0aRP69esX+XvSpEkAgDFjxmDRokWYPHkyysvLcd1116G4uBiXXHIJVq1ahYSEBNXrVAZCCBruoEnYPDKl3KeMQPGbZ+A4HLoYjLCYx32UV1So+q5UtPcHdPMEyjgWzW52WLEsge9O/Tcehy5dBekJ5iM/UuFX9V1WpYwnUsxzTTQVACiTYVQ0UUlVPt1vBRMTEo3blleUq/p2KN8aHYptWcQ8tgcAEhPMI4rcHt24vYr3ZZfLfBpDhtlh6gJ06aWXHnejdzgcmDlzJmbOnKntmoiIziDWz4IjIqIzEwsQERFZwQJERERWsAAREZEVLEBERGQFCxAREVnBAkRERFawABERkRUsQEREZAULEBERWaGO4jlVysqrEBdnllEWUkSZBZXBVy6Xeb5bKKTL9yo7Yp5PVVGpy8kyzWKqCxd0oWqavDZNW0AXS+eO0/WdmmjefucBXZ6eKLLDvnuCqnPlWBTLR9Uz4FCsK36fT9W3NynJuK3LqfusHfDrlqdD8VneoZyLIubbcljcqr6dDvPlExdnPo0Bw3xJ7gEREZEVLEBERGQFCxAREVnBAkRERFawABERkRUsQEREZAULEBERWcECREREVrAAERGRFSxARERkRYON4qmsDCLOcHROZ7xxv64487YA4Pf7jduWlR1R9V2liB4JiS7mR0MTxwHo43LCYfOxa/t2KT5CNfGquobAPI6lIqj7LCfqOJaGEWekpRmLNj6qsrLSuG1iYqKq77KyMlV70+gZQBfbA+jmYTCoixByOs2jxjwwbxs0XJbcAyIiIitYgIiIyAoWICIisoIFiIiIrGABIiIiK1iAiIjIChYgIiKyggWIiIisYAEiIiIrWICIiMgKFiAiIrKiwWbBOePccBqGwTmd5nW0vLxCNQ5N+4A/oOpbk+8mDl1il0OR7xZWZochFLtcOs24AcCtWIMzknTjPqSJ9gsr56E2r62RZsFplqd23FVVVcZtvV5dEGCcaRDl/wkGzdctH3TrocB8HgZ85vl4AFCpmIeZzTOM25pm0nEPiIiIrGABIiIiK1iAiIjIChYgIiKyggWIiIisYAEiIiIrWICIiMgKFiAiIrKCBYiIiKxgASIiIisabhSP87ubibKyUuN+y8vNoycAIBAMGbeVsC5iQxM641RG1GiSe8KKSCCgDlEviqE7dZMJr0fxBOV0Hj6iib9RDlwZgNNQoni0UUnasWiEQubbZmWlLqImKSlJ1b6kpMS4bTis+9wfDJrPc4fTreq7tLTMvLFi0ZsuG+4BERGRFSxARERkhboAvfPOO7jiiiuQm5sLh8OBlStXRj0+duxYOByOqNvgwYPra7xERHSaUBeg8vJydOvWDXPnzq21zeDBg7Fv377IbenSpSc1SCIiOv2oT0IoKChAQUHBcdt4PB5kZ2fXeVBERHT6i8kxoLVr1yIzMxPt27fHjTfeiEOHDtXa1ufzobS0NOpGRESnv3ovQIMHD8bzzz+P1atX46GHHsK6detQUFBQ62l5hYWFSEtLi9zy8vLqe0hERNQA1fvvgEaNGhX5/3nnnYeuXbuiXbt2WLt2Lfr371+t/dSpUzFp0qTI36WlpSxCRERngJifht22bVs0a9YM27dvr/Fxj8eD1NTUqBsREZ3+Yl6A9uzZg0OHDiEnJyfWL0VERI2I+iu4I0eORO3N7Ny5E1u2bEFGRgYyMjIwY8YMDB8+HNnZ2dixYwcmT56Ms88+G4MGDarXgRMRUeOmLkCbNm1Cv379In8fPX4zZswYzJ8/H1u3bsVzzz2H4uJi5ObmYuDAgbj//vvh8XhUr3P428NwuVxGbf3+oHG/fkW2GwCEw4osK2XuVZzh9NWl75Aily6WeV0AIIr8MG3WWFqi+XQe8emW/RGfeduwch6GlbmB2uy4WInluhLLnLmKigpV316vV9Xe9L0KAIJB8/crAAgqpjPepftSy+NJNG57+Fvz3DjT9VtdgC699NLjLvg33nhD2yUREZ2BmAVHRERWsAAREZEVLEBERGQFCxAREVnBAkRERFawABERkRUsQEREZAULEBERWcECREREVrAAERGRFfV+PaD6UlnpN85X0uS1abOsNO2dyiyrWI1D216d7xXD6fTG68bijTPPVNtTpht3SBHXJqLLdtMvT1XzmGlIWXAatV0QszaxzI4rLi5W9S2K3MCQch7GxbmN2yYkmC970yw47gEREZEVLEBERGQFCxAREVnBAkRERFawABERkRUsQEREZAULEBERWcECREREVrAAERGRFSxARERkRYON4gmFBIBZ9IMqdkY5DqfLvEY7oYvBCCviWzRxHIB+OmNJE1HUJFHXdzhkPqWlunQVIIYRT1qx7r8haEiTqI3iad68uXHbuDjd224gEDBu63Do9ikcivcst8dj3NY0+oh7QEREZAULEBERWcECREREVrAAERGRFSxARERkBQsQERFZwQJERERWsAAREZEVLEBERGQFCxAREVnBAkRERFY02Cw4x//9M2tsHiLlUuYwuRPM84+CAb+q74DPLC8JAHRJcNpcLV2GnSLaDQDgjjMfTJJHN6UllebtKwO6sDFRJOo15qy2hjJy7SzU5Z7pVtpgMKhqr8mOS05OVvV9+PBh47aafEkAqpkuYfN5GDbMruQeEBERWcECREREVrAAERGRFSxARERkBQsQERFZwQJERERWsAAREZEVLEBERGQFCxAREVnBAkRERFY02Cgep8sBp8ss+sHpijfuNzEpSTWOuHjzWVQeMo/WAYCAIh7E4VTm34Q1MTK6+A4nXKr2KQnm88UB3Tw8pIjiCWnzjBS0UTyxbO/QZiVp4lh0PavEcNjQj1zXvry83LhtZmamqu84RXyYNkJINdPFfH8lbLhwuAdERERWsAAREZEVqgJUWFiIHj16ICUlBZmZmRg6dCi2bdsW1aaqqgoTJkxA06ZNkZycjOHDh2P//v31OmgiImr8VAVo3bp1mDBhAjZs2IA333wTgUAAAwcOjPr+8/bbb8err76K5cuXY926ddi7dy+GDRtW7wMnIqLGTXUSwqpVq6L+XrRoETIzM7F582b06dMHJSUl+N3vfoclS5bgsssuAwAsXLgQHTt2xIYNG3DRRRdV69Pn88Hn80X+Li0trct0EBFRI3NSx4BKSkoAABkZGQCAzZs3IxAIYMCAAZE2HTp0QKtWrbB+/foa+ygsLERaWlrklpeXdzJDIiKiRqLOBSgcDuO2225D79690aVLFwBAUVER3G430tPTo9pmZWWhqKioxn6mTp2KkpKSyG337t11HRIRETUidf4d0IQJE/Dpp5/i3XffPakBeDweeDzml70mIqLTQ532gCZOnIjXXnsNa9asQcuWLSP3Z2dnw+/3o7i4OKr9/v37kZ2dfVIDJSKi04uqAIkIJk6ciBUrVuDtt99GmzZtoh7v3r074uPjsXr16sh927Ztw65du5Cfn18/IyYiotOC6iu4CRMmYMmSJXjllVeQkpISOa6TlpaGxMREpKWlYdy4cZg0aRIyMjKQmpqKm2++Gfn5+TWeAUdERGcuVQGaP38+AODSSy+Nun/hwoUYO3YsAODRRx+F0+nE8OHD4fP5MGjQIMybN089MKfru5uJuDhNNpku48l/zCniJxJWZsE5FfluErsoOIiy83iXbh6mus3bB4K6vssqNTlmMQ0bU3bdcPqOZb7bmUKTwVZVVaXqOzk52bjt4cOHVX1rYiDFodnWzNqqCpDJip2QkIC5c+di7ty5mq6JiOgMwyw4IiKyggWIiIisYAEiIiIrWICIiMgKFiAiIrKCBYiIiKxgASIiIitYgIiIyAoWICIisqLOl2OINafDCafDrD46FBErAb95tA4AhILmWRUSVuRaAIBDEQ2jjFcJK8bi0IwDgNeja+9RRPeUVuimMxAwbyua3BFAlVETy2gdLfVYFMtf27du3dLOQ+XyjCHNfDlSVqbqOzMr07ht2RFd36GQeYSQZhpN23IPiIiIrGABIiIiK1iAiIjIChYgIiKyggWIiIisYAEiIiIrWICIiMgKFiAiIrKCBYiIiKxgASIiIitYgIiIyIoGmwXncrjgcriM2krYPKNIk5EGAKFQSNVeRZGtFFbmmGnaxznN5vNRKQnKDK6w+TwsVmbBKRa9OmqsUee76TqPXd8K2qw+h2KBOgxzJf87GF1zTZ5eUBNgCMDnM8+vTElJVvVdXFxs3Daser9iFhwRETVgLEBERGQFCxAREVnBAkRERFawABERkRUsQEREZAULEBERWcECREREVrAAERGRFSxARERkRYON4hER4/iRkCLqJaSM4tFG96iYp3fox+Ewj83wxOv69jiDqvaBoPlYjlQpZgqUETXKyBlN39qonAYV8xPLvhXT6VDE2cSaOolH1beu99LSUuO2zTObq/o+cuSIcdtgDGLJuAdERERWsAAREZEVLEBERGQFCxAREVnBAkRERFawABERkRUsQEREZAULEBERWcECREREVrAAERGRFSxARERkRYPNggspcoc0WXDaTLXYJnbFLvsqPs580aYlaueJrn2Z37xtVUiZeaeKgmtIWXCq5tBMaExj5hpQXpuKdqbEcjqVQ/H7zTegQCCg6js5Odm4bUlJiXFb07nHPSAiIrJCVYAKCwvRo0cPpKSkIDMzE0OHDsW2bdui2lx66aVwOBxRtxtuuKFeB01ERI2fqgCtW7cOEyZMwIYNG/Dmm28iEAhg4MCBKC8vj2o3fvx47Nu3L3KbPXt2vQ6aiIgaP9UxoFWrVkX9vWjRImRmZmLz5s3o06dP5P6kpCRkZ2fXzwiJiOi0dFLHgI4elMrIyIi6f/HixWjWrBm6dOmCqVOnoqKiotY+fD4fSktLo25ERHT6q/NZcOFwGLfddht69+6NLl26RO6/+uqr0bp1a+Tm5mLr1q2YMmUKtm3bhpdffrnGfgoLCzFjxoy6DoOIiBoph9Tx2sA33ngjXn/9dbz77rto2bJlre3efvtt9O/fH9u3b0e7du2qPe7z+eDz+SJ/l5aWIi8vDx3ad4HL5TIaS6M9DVtxqmdQMY0A4HKZ79w2T9bNk1S34rxqAGWV5m3/fUg5xxVDF1Eu+zPkNGxV8xienqy9JLdT0V7TFgBE2V4zdvXXTk7zvjOzMlVda07b1pyGHQ6HsOfrr1BSUoLU1NRa29VpD2jixIl47bXX8M477xy3+ABAr169AKDWAuTxeODxeOoyDCIiasRUBUhEcPPNN2PFihVYu3Yt2rRpc8LnbNmyBQCQk5NTpwESEdHpSVWAJkyYgCVLluCVV15BSkoKioqKAABpaWlITEzEjh07sGTJElx++eVo2rQptm7dittvvx19+vRB165dYzIBRETUOKkK0Pz58wF892PTYy1cuBBjx46F2+3GW2+9hcceewzl5eXIy8vD8OHDcc8999TbgImI6PSg/gruePLy8rBu3bqTGtBRwVDI+OBoWHFwuSFFQmmO/jqU43YpDlwmu3Wdh8O69iUVipmoPjqvWUDahRnbJECNWOa7aeZKWJQH5xXzUNP2uyfEbuOMZUaZ/vwT82eUluh+xtKsWTPjtt8PHDiecMhs2TALjoiIrGABIiIiK1iAiIjIChYgIiKyggWIiIisYAEiIiIrWICIiMgKFiAiIrKCBYiIiKxgASIiIivqfEG6WAtLGA7D2A9NNIz2miMxjUBRDMWhjJFJije/zgeU18kJ6S5NhCNViicoo14ayjV7YrmeaNXxEl+mveuaxzDKShXCFNNMLahWAPW1hhRT6vPprtUVDJpvmykptV/X5/tCoaBRO+4BERGRFSxARERkBQsQERFZwQJERERWsAAREZEVLEBERGQFCxAREVnBAkRERFawABERkRUsQEREZAULEBERWdFgs+BERJHxpskDq9t4TMQyb8qp/KiQEm8+oSFluFu5Lm4KgaBmpmvnYSyz4DTtY5czpx+LlqZvXW6gZnnGchK18y/m2XExop3O0tJS47aZWZnGbYNBZsEREVEDxgJERERWsAAREZEVLEBERGQFCxAREVnBAkRERFawABERkRUsQEREZAULEBERWcECREREVjTgKJ4wREzjMDSxGbHL+1CHdyjiPtwuXdfxTvPpDIvuc0hpuTKOxXg5AqJePrGMqGmc9LE9ijgjdeSQ+bLXbj+auBynMsuqIUXxaMaiHbfP5zNu6/cHjNuGGMVDREQNGQsQERFZwQJERERWsAAREZEVLEBERGQFCxAREVnBAkRERFawABERkRUsQEREZAULEBERWcECREREVjTYLLhYaUjJYRIOGbdNStSNPKDI4NLOlHKfLgtOkx/mUI5Fl3umzTFTtVb2rZyHMVxxNfNQnQWnaazMMZOwee9xDt1bnXY9dDjMP8trP/Vr5kosE+yKi0uN24ZCZu9t3AMiIiIrVAVo/vz56Nq1K1JTU5Gamor8/Hy8/vrrkcerqqowYcIENG3aFMnJyRg+fDj2799f74MmIqLGT1WAWrZsiVmzZmHz5s3YtGkTLrvsMgwZMgSfffYZAOD222/Hq6++iuXLl2PdunXYu3cvhg0bFpOBExFR4+YQ/cVDomRkZGDOnDkYMWIEmjdvjiVLlmDEiBEAgC+++AIdO3bE+vXrcdFFFxn1V1pairS0NJzV5mw4naYXwdFcbyZ2XOpriJiPpolXN/JEt+IYg3IV+Hq/+XVBACAQahjHgLTHLxSHGMBjQLW1V1BuP05F+ziX7hiQS339IPP22mv2OBRjiWXfnoQk47ahUAg7tm1FSUkJUlNTa21X52NAoVAIL774IsrLy5Gfn4/NmzcjEAhgwIABkTYdOnRAq1atsH79+lr78fl8KC0tjboREdHpT12APvnkEyQnJ8Pj8eCGG27AihUr0KlTJxQVFcHtdiM9PT2qfVZWFoqKimrtr7CwEGlpaZFbXl6eeiKIiKjxUReg9u3bY8uWLdi4cSNuvPFGjBkzBp9//nmdBzB16lSUlJREbrt3765zX0RE1Hiofwfkdrtx9tlnAwC6d++ODz74AI8//jhGjhwJv9+P4uLiqL2g/fv3Izs7u9b+PB4PPB6PfuRERNSonfTvgMLhMHw+H7p37474+HisXr068ti2bduwa9cu5Ofnn+zLEBHRaUa1BzR16lQUFBSgVatWKCsrw5IlS7B27Vq88cYbSEtLw7hx4zBp0iRkZGQgNTUVN998M/Lz843PgCMiojOHqgAdOHAAo0ePxr59+5CWloauXbvijTfewI9+9CMAwKOPPgqn04nhw4fD5/Nh0KBBmDdvXp0GFg6HYXp6teYUSPVZ56rTGpWnYSvOOU6I0522Gwqat/f5g6q+A4q+Ad2puOrTjRVPCGtPfY5h6+/Wb41Yhqwo6M5NB5zm41bPE8W2GRLdOg6X6U9AjjY3H4v2VGnNOq4+DVuxXgX85j+/CBvGjJ3074Dq29HfAbVq3db4d0ANpQDFKcbxXd/mG1xOmm7j1GzM2gL0n29j+EbOAlSLhlGARDlu0RQg5bap+R2QS7ltutQFyPyzvFP9GyPz6VT3bfxbS8DhNJ/GcDiEf3/1z9j9DoiIiOhksAAREZEVLEBERGQFCxAREVnBAkRERFawABERkRUsQEREZAULEBERWcECREREVqjTsGPtaFKB5pfiDkWkTSyTEMLay3kqkhCCIW0SgvlYQuq+mYRwsq0baxICtPMwrLhasXLbFNW2qepaH2mj2Ja1dGPRzUNd0JgmVum7KJ4TLdMGV4DKysoAAHt2f213IA3MV7YHQESkVFZWhrS0tFofb3BZcOFwGHv37kVKSkpU5S8tLUVeXh5279593Gyhxo7Tefo4E6YR4HSebupjOkUEZWVlyM3NPW4+XYPbA3I6nWjZsmWtj6empp7WC/8oTufp40yYRoDTebo52ek83p7PUTwJgYiIrGABIiIiKxpNAfJ4PJg2bRo8Ho/tocQUp/P0cSZMI8DpPN2cyulscCchEBHRmaHR7AEREdHphQWIiIisYAEiIiIrWICIiMgKFiAiIrKi0RSguXPn4qyzzkJCQgJ69eqFf/zjH7aHVK+mT58Oh8MRdevQoYPtYZ2Ud955B1dccQVyc3PhcDiwcuXKqMdFBPfddx9ycnKQmJiIAQMG4Msvv7Qz2JNwoukcO3ZstWU7ePBgO4Oto8LCQvTo0QMpKSnIzMzE0KFDsW3btqg2VVVVmDBhApo2bYrk5GQMHz4c+/fvtzTiujGZzksvvbTa8rzhhhssjbhu5s+fj65du0bSDvLz8/H6669HHj9Vy7JRFKBly5Zh0qRJmDZtGj788EN069YNgwYNwoEDB2wPrV517twZ+/bti9zeffdd20M6KeXl5ejWrRvmzp1b4+OzZ8/GE088gaeffhobN26E1+vFoEGDUFVVdYpHenJONJ0AMHjw4Khlu3Tp0lM4wpO3bt06TJgwARs2bMCbb76JQCCAgQMHory8PNLm9ttvx6uvvorly5dj3bp12Lt3L4YNG2Zx1Hom0wkA48ePj1qes2fPtjTiumnZsiVmzZqFzZs3Y9OmTbjsssswZMgQfPbZZwBO4bKURqBnz54yYcKEyN+hUEhyc3OlsLDQ4qjq17Rp06Rbt262hxEzAGTFihWRv8PhsGRnZ8ucOXMi9xUXF4vH45GlS5daGGH9+P50ioiMGTNGhgwZYmU8sXLgwAEBIOvWrROR75ZdfHy8LF++PNLmn//8pwCQ9evX2xrmSfv+dIqI9O3bV2699VZ7g4qRJk2ayLPPPntKl2WD3wPy+/3YvHkzBgwYELnP6XRiwIABWL9+vcWR1b8vv/wSubm5aNu2LX7+859j165dtocUMzt37kRRUVHUck1LS0OvXr1Ou+UKAGvXrkVmZibat2+PG2+8EYcOHbI9pJNSUlICAMjIyAAAbN68GYFAIGp5dujQAa1atWrUy/P703nU4sWL0axZM3Tp0gVTp05FRUWFjeHVi1AohBdffBHl5eXIz88/pcuywaVhf98333yDUCiErKysqPuzsrLwxRdfWBpV/evVqxcWLVqE9u3bY9++fZgxYwZ++MMf4tNPP0VKSort4dW7oqIiAKhxuR597HQxePBgDBs2DG3atMGOHTvw61//GgUFBVi/fj1cLpft4amFw2Hcdttt6N27N7p06QLgu+XpdruRnp4e1bYxL8+aphMArr76arRu3Rq5ubnYunUrpkyZgm3btuHll1+2OFq9Tz75BPn5+aiqqkJycjJWrFiBTp06YcuWLadsWTb4AnSmKCgoiPy/a9eu6NWrF1q3bo0//vGPGDdunMWR0ckaNWpU5P/nnXceunbtinbt2mHt2rXo37+/xZHVzYQJE/Dpp582+mOUJ1LbdF533XWR/5933nnIyclB//79sWPHDrRr1+5UD7PO2rdvjy1btqCkpAQvvfQSxowZg3Xr1p3SMTT4r+CaNWsGl8tV7QyM/fv3Izs729KoYi89PR3nnnsutm/fbnsoMXF02Z1pyxUA2rZti2bNmjXKZTtx4kS89tprWLNmTdR1u7Kzs+H3+1FcXBzVvrEuz9qmsya9evUCgEa3PN1uN84++2x0794dhYWF6NatGx5//PFTuiwbfAFyu93o3r07Vq9eHbkvHA5j9erVyM/Ptziy2Dpy5Ah27NiBnJwc20OJiTZt2iA7OztquZaWlmLjxo2n9XIFgD179uDQoUONatmKCCZOnIgVK1bg7bffRps2baIe7969O+Lj46OW57Zt27Br165GtTxPNJ012bJlCwA0quVZk3A4DJ/Pd2qXZb2e0hAjL774ong8Hlm0aJF8/vnnct1110l6eroUFRXZHlq9ueOOO2Tt2rWyc+dOee+992TAgAHSrFkzOXDggO2h1VlZWZl89NFH8tFHHwkAeeSRR+Sjjz6Sf//73yIiMmvWLElPT5dXXnlFtm7dKkOGDJE2bdpIZWWl5ZHrHG86y8rK5M4775T169fLzp075a233pILLrhAzjnnHKmqqrI9dGM33nijpKWlydq1a2Xfvn2RW0VFRaTNDTfcIK1atZK3335bNm3aJPn5+ZKfn29x1Honms7t27fLzJkzZdOmTbJz50555ZVXpG3bttKnTx/LI9e5++67Zd26dbJz507ZunWr3H333eJwOORvf/ubiJy6ZdkoCpCIyJNPPimtWrUSt9stPXv2lA0bNtgeUr0aOXKk5OTkiNvtlhYtWsjIkSNl+/bttod1UtasWSMAqt3GjBkjIt+din3vvfdKVlaWeDwe6d+/v2zbts3uoOvgeNNZUVEhAwcOlObNm0t8fLy0bt1axo8f3+g+PNU0fQBk4cKFkTaVlZVy0003SZMmTSQpKUl++tOfyr59++wNug5ONJ27du2SPn36SEZGhng8Hjn77LPlrrvukpKSErsDV7r22muldevW4na7pXnz5tK/f/9I8RE5dcuS1wMiIiIrGvwxICIiOj2xABERkRUsQEREZAULEBERWcECREREVrAAERGRFSxARERkBQsQERFZwQJERERWsAAREZEVLEBERGTF/wc9dcOyaFCjCwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"DATASET\"\"\"\n",
    "\n",
    "try:\n",
    "    from google.colab import drive\n",
    "    drive.mount(\"/content/drive\")\n",
    "    DATA_DIR = save_dir\n",
    "    LABELS_PATH = DATA_DIR/\"data.txt\"\n",
    "except:\n",
    "    DATA_DIR = save_dir\n",
    "    if not DATA_DIR.exists():\n",
    "        print(\"Dataset doesnt exist or not preprocessed\")\n",
    "    else:\n",
    "        LABELS_PATH = DATA_DIR/\"data.txt\"\n",
    "!pip install imageio\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from pathlib import Path\n",
    "import imageio as iio\n",
    "from torchvision.transforms import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "class DrivingDataset(Dataset):\n",
    "    def __init__(self, labels_path, data_dir, transform=None):\n",
    "        with open(Path(labels_path), \"r\") as f:\n",
    "            self.labels = f.readlines()\n",
    "            f.close()\n",
    "        self.data_dir = Path(data_dir)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def __getitem__(self, index) :\n",
    "        img_path, label = self.labels[index].split()\n",
    "        label=float(label)\n",
    "        img = iio.imread(self.data_dir/img_path)\n",
    "\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        return (img, label)\n",
    "        \n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Resize((32,32)),\n",
    "    # transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "])\n",
    "\n",
    "dataset = DrivingDataset(labels_path=LABELS_PATH, data_dir=DATA_DIR, transform=transform)\n",
    "# print(len(dataset))\n",
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = int(len(dataset)-train_size)\n",
    "train_set, test_set = random_split(dataset, [train_size, test_size])\n",
    "train_loader = DataLoader(train_set, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_set, batch_size=32, shuffle=False)\n",
    "\n",
    "for i, (imgs, labels) in enumerate(train_loader):\n",
    "    img = imgs[0]\n",
    "    label = labels[0]\n",
    "    plt.imshow(np.transpose(img,  (1, 2, 0)))\n",
    "    plt.title(label)\n",
    "    # plt.axis('off')\n",
    "    plt.show()\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"MODEL\"\"\"\n",
    "\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "\n",
    "\"\"\"MODEL\"\"\"\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "\n",
    "class NewGELUActivation(nn.Module):\n",
    "    \"\"\"\n",
    "    Implementation of the GELU activation function currently in Google BERT repo (identical to OpenAI GPT). Also see\n",
    "    the Gaussian Error Linear Units paper: https://arxiv.org/abs/1606.08415\n",
    "\n",
    "    Taken from https://github.com/huggingface/transformers/blob/main/src/transformers/activations.py\n",
    "    \"\"\"\n",
    "\n",
    "    def forward(self, input):\n",
    "        return 0.5 * input * (1.0 + torch.tanh(math.sqrt(2.0 / math.pi) * (input + 0.044715 * torch.pow(input, 3.0))))\n",
    "\n",
    "\n",
    "class PatchEmbeddings(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.img_size = config[\"img_size\"]\n",
    "        self.num_channels = config[\"num_channels\"]\n",
    "        self.patch_size = config[\"patch_size\"]\n",
    "        self.embed_dim = config[\"embed_dim\"]\n",
    "        \n",
    "        self.num_patches = (self.img_size//self.patch_size)**2\n",
    "        self.projection = nn.Conv2d(self.num_channels, self.embed_dim, kernel_size=self.patch_size, stride=self.patch_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.projection(x)\n",
    "        # print(x.shape)\n",
    "        x = x.flatten(2).transpose(1,2)\n",
    "        return x\n",
    "\n",
    "\n",
    "class Embeddings(nn.Module):\n",
    "    # Patch Embeddings + (CLS Token + Positional Embeddings )\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.patch_embeddings = PatchEmbeddings(config)\n",
    "        self.embed_dim = config[\"embed_dim\"]\n",
    "        self.cls_token = nn.Parameter(torch.randn(1,1,self.embed_dim))\n",
    "        self.positional_embeddings = nn.Parameter(torch.randn(1, self.patch_embeddings.num_patches+1, self.embed_dim))\n",
    "        self.dropout = nn.Dropout(config[\"dropout\"])\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.patch_embeddings(x)\n",
    "        batch_size, _, _ = x.size()\n",
    "        cls_token = self.cls_token.expand(batch_size, -1, -1) # (1, 1, hidden_size) -> (batch_size, 1, hidden_size)\n",
    "        x = torch.cat((cls_token, x), dim=1)\n",
    "        x = x + self.positional_embeddings\n",
    "        x = self.dropout(x)\n",
    "        return x\n",
    "\n",
    "class AttentionHead(nn.Module):\n",
    "    def __init__(self, attention_head_size,config):\n",
    "        super().__init__()\n",
    "        self.embed_dim = config[\"embed_dim\"]\n",
    "        self.attention_head_size = attention_head_size\n",
    "        self.bias = config[\"bias\"]\n",
    "        \n",
    "        self.query = nn.Linear(self.embed_dim, self.attention_head_size, bias=self.bias)\n",
    "        self.key = nn.Linear(self.embed_dim, self.attention_head_size, bias=self.bias)\n",
    "        self.value = nn.Linear(self.embed_dim, self.attention_head_size, bias=self.bias)\n",
    "\n",
    "        self.dropout = nn.Dropout(config[\"dropout\"])\n",
    "\n",
    "    def forward(self, x):\n",
    "        q = self.query(x)\n",
    "        k = self.key(x)\n",
    "        v = self.value(x)\n",
    "\n",
    "        attention_scores = torch.matmul(q, k.transpose(-1,-2))\n",
    "        attention_scores = attention_scores / math.sqrt(self.attention_head_size)\n",
    "        attention_scores = nn.functional.softmax(attention_scores, dim=-1)\n",
    "        attention_scores = self.dropout(attention_scores)\n",
    "        attention_out = torch.matmul(attention_scores, v)\n",
    "        \n",
    "        return attention_out\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.embed_dim = config[\"embed_dim\"]\n",
    "        self.num_heads = config[\"num_heads\"]\n",
    "        self.head_size = self.embed_dim//self.num_heads\n",
    "        self.all_head_size = self.head_size * self.num_heads\n",
    "        self.dropout = config[\"dropout\"]\n",
    "        self.qkv_bias = config[\"bias\"]\n",
    "\n",
    "        self.heads = nn.ModuleList([\n",
    "            AttentionHead(\n",
    "                self.head_size,\n",
    "                config\n",
    "            ) for _ in range(self.num_heads)\n",
    "        ])\n",
    "\n",
    "        self.attention_mlp = nn.Linear(self.all_head_size, self.embed_dim)\n",
    "        self.out_dropout = nn.Dropout(config[\"dropout\"])\n",
    "\n",
    "    def forward(self, x):\n",
    "        attention_outputs = [head(x) for head in self.heads]\n",
    "        attention_output = torch.cat([attention_output for attention_output in attention_outputs], dim=-1) #concat attention for each head\n",
    "        attention_output = self.attention_mlp(attention_output)\n",
    "        attention_output = self.out_dropout(attention_output)\n",
    "\n",
    "        return attention_output\n",
    "        \n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.embed_dim = config[\"embed_dim\"]\n",
    "        self.hidden_dim = config[\"hidden_dim\"]\n",
    "        self.fc1 = nn.Linear(self.embed_dim, self.hidden_dim)\n",
    "        # self.act = nn.GELU()\n",
    "        self.act=NewGELUActivation()\n",
    "        self.fc2 = nn.Linear(self.hidden_dim, self.embed_dim)\n",
    "        self.dropout=nn.Dropout(config[\"dropout\"])\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.act(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.dropout(x)\n",
    "        return x\n",
    "\n",
    "class Block(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.embed_dim=config[\"embed_dim\"]\n",
    "        self.num_heads = config[\"num_heads\"]\n",
    "        self.hidden_dim = config[\"hidden_dim\"]\n",
    "        self.attention = MultiHeadAttention(config)\n",
    "        self.layer_norm1 = nn.LayerNorm(self.embed_dim)\n",
    "        self.mlp = MLP(config)\n",
    "        self.layer_norm2 = nn.LayerNorm(self.embed_dim)\n",
    "\n",
    "    def forward(self,x):\n",
    "        attention_output = self.attention(self.layer_norm1(x))\n",
    "        x = x+attention_output\n",
    "        mlp_out = self.mlp(self.layer_norm2(x))\n",
    "        x = x+mlp_out\n",
    "        return x\n",
    "        \n",
    "    \n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self,config):\n",
    "        super().__init__()\n",
    "        self.blocks = nn.ModuleList([Block(config) for _ in range(config[\"num_hidden_layers\"])])\n",
    "    def forward(self,x ):\n",
    "        all_attentions = []\n",
    "        for block in self.blocks:\n",
    "            x = block(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class ViT(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.img_size = config[\"img_size\"]\n",
    "        self.embed_dim = config[\"embed_dim\"]\n",
    "        self.num_classes = config[\"num_classes\"]\n",
    "    \n",
    "        self.embeddings = Embeddings(config)\n",
    "        self.encoder = Encoder(config)\n",
    "    \n",
    "        self.classifier = nn.Linear(self.embed_dim, self.num_classes)\n",
    "\n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "    def forward(self, x):\n",
    "        embedding_output = self.embeddings(x)\n",
    "        encoder_output = self.encoder(embedding_output)\n",
    "        classification = self.classifier(encoder_output[:, 0, :])\n",
    "        return classification\n",
    "\n",
    "\n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, (nn.Linear, nn.Conv2d)):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "            if module.bias is not None:\n",
    "                torch.nn.init.zeros_(module.bias)\n",
    "        elif isinstance(module, nn.LayerNorm):\n",
    "            module.bias.data.zero_()\n",
    "            module.weight.data.fill_(1.0)\n",
    "        elif isinstance(module, Embeddings):\n",
    "            module.positional_embeddings.data = nn.init.trunc_normal_(\n",
    "                module.positional_embeddings.data.to(torch.float32),\n",
    "                mean=0.0,\n",
    "                std=0.02,\n",
    "            ).to(module.positional_embeddings.dtype)\n",
    "\n",
    "            module.cls_token.data = nn.init.trunc_normal_(\n",
    "                module.cls_token.data.to(torch.float32),\n",
    "                mean=0.0,\n",
    "                std=0.02,\n",
    "            ).to(module.cls_token.dtype)\n",
    "\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"UTILS\"\"\"\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "CHECKPOINT_DIR = root_dir/\"e2e_steering_ckpt\"\n",
    "EXPERIMENT_DIR = root_dir/\"experiments\"\n",
    "\n",
    "def save_checkpoint(state_dict, epoch, path):\n",
    "    p = Path(path)\n",
    "    if not p.exists():\n",
    "        print(\"Creating folder\")\n",
    "        p.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    model_details = {\n",
    "        \"epoch\":epoch,\n",
    "        \"state_dict\": state_dict,\n",
    "    }\n",
    "    torch.save(model_details, f\"{p}/vit_cifar10_{epoch}.pth\")\n",
    "    print(f\"model saved at path : {p}/vit_cifar10_{epoch}.pth\")\n",
    "\n",
    "\n",
    "def load_pretrained(model, path, epoch):\n",
    "    model.load_state_dict(torch.load(f\"{path}/vit_cifar10_{epoch}.pth\")[\"state_dict\"])\n",
    "    return model\n",
    "\n",
    "def save_experiment(model, epoch, config, train_losses, test_losses, accuracies, path):\n",
    "    exp_data = {\n",
    "        \"train_losses\":train_losses,\n",
    "        \"test_losses\":test_losses,\n",
    "        \"accuracies\":accuracies,\n",
    "        \"epoch\":epoch,\n",
    "    }\n",
    "    exp_name = config[\"exp_name\"]\n",
    "    config_file = path/f\"{exp_name}\"/\"config.json\"\n",
    "    metrics_file = path/f\"{exp_name}\"/\"metrics.json\"\n",
    "    files = [config_file , metrics_file]\n",
    "    for file in files:\n",
    "        if file.exists():\n",
    "            print(f\"{file} exists\")\n",
    "        else:\n",
    "            file.parent.mkdir(parents=True, exist_ok=True)\n",
    "            file.touch()\n",
    "            print(f\"{file} created\")\n",
    "\n",
    "    with open(config_file, \"w\") as f:\n",
    "        json.dump(config, f, sort_keys=True, indent=4)\n",
    "    with open(metrics_file, \"w\") as f:\n",
    "        json.dump(exp_data, f, sort_keys=True, indent=4)\n",
    "\n",
    "    save_checkpoint(model.state_dict(), epoch, path/f\"{exp_name}\")\n",
    "\n",
    "def load_experiment(model ,exp_name, path):\n",
    "    with open(path/f\"{exp_name}\"/\"metrics.json\", 'r') as file:\n",
    "      data = json.load(file)\n",
    "    train_losses=data[\"train_losses\"]\n",
    "    test_losses=data[\"test_losses\"]\n",
    "    accuracies=data[\"accuracies\"]\n",
    "    epoch=data[\"epoch\"]\n",
    "\n",
    "    model = load_pretrained(model, path/exp_name, epoch)\n",
    "\n",
    "    return model, train_losses, test_losses, accuracies, epoch\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"CONFIG\"\"\"\n",
    "\n",
    "\n",
    "config = {\n",
    "    \"img_size\":32,\n",
    "    \"patch_size\":4,\n",
    "    \"num_channels\":3,\n",
    "    \"embed_dim\":48*16,\n",
    "    \"dropout\":0.0,\n",
    "    \"bias\":True,\n",
    "    \"num_heads\":4,\n",
    "    \"hidden_dim\":4*48*16,\n",
    "    \"num_hidden_layers\":9,\n",
    "    \"num_classes\":1,\n",
    "    \"device\":\"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "    \"exp_name\" : 'e2e--10-epochs',\n",
    "    \"num_epochs\":10,\n",
    "    \"lr\":0.01,\n",
    "    \"save_model_every\" :0\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "import torch\n",
    "class Trainer:\n",
    "    def __init__(self, model, optimizer, criterion, device, path=CHECKPOINT_DIR):\n",
    "        self.model = model.to(device)\n",
    "        self.optimizer = optimizer\n",
    "        self.criterion = criterion\n",
    "        self.device = device\n",
    "        self.path=path\n",
    "        self.exp_dir = EXPERIMENT_DIR\n",
    "\n",
    "    def train(self, train_loader, test_loader, num_epochs, save_model_every_n_epochs=0):\n",
    "        train_losses = []\n",
    "        test_losses = []\n",
    "        accuracies = [] \n",
    "\n",
    "        for i in range(num_epochs):\n",
    "            train_loss = self.train_epoch(train_loader)\n",
    "            accuracy, test_loss = self.evaluate(test_loader)\n",
    "            train_losses.append(train_loss)\n",
    "            test_losses.append(test_loss)\n",
    "            accuracies.append(accuracy)\n",
    "            print(f\"Epoch: {i+1}, Train loss: {train_loss:.4f}, Test loss: {test_loss:.4f}, Accuracy: {accuracy:.4f}\")\n",
    "            if save_model_every_n_epochs > 0 and (i+1) % save_model_every_n_epochs == 0 and i+1 != num_epochs:\n",
    "                print('\\tSave checkpoint at epoch', i+1)\n",
    "                save_checkpoint(self.model.state_dict(), i+1, train_losses, test_losses, accuracies, self.path)\n",
    "\n",
    "        save_experiment(self.model, num_epochs, config, train_losses, test_losses, accuracies, self.exp_dir)\n",
    "\n",
    "    def train_epoch(self, train_loader):\n",
    "        self.model.train()\n",
    "        total_loss = 0\n",
    "        for i, (imgs, labels) in enumerate(train_loader):\n",
    "            imgs = imgs.to(self.device)\n",
    "            labels = torch.tensor(labels).float().to(self.device)\n",
    "            \n",
    "            self.optimizer.zero_grad()\n",
    "            predictions = self.model(imgs).view(32).float()\n",
    "            loss = self.criterion(predictions, labels)\n",
    "            print(labels.shape, predictions.shape)\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            total_loss += loss.item()* len(imgs)\n",
    "\n",
    "        return total_loss / len(train_loader.dataset)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def evaluate(self, test_loader):\n",
    "        self.model.eval()\n",
    "        total_loss = 0\n",
    "        correct = 0\n",
    "        with torch.no_grad():\n",
    "            for i, (imgs, labels) in enumerate(test_loader):\n",
    "                imgs = imgs.to(self.device)\n",
    "                labels = torch.tensor(labels).float().to(self.device)\n",
    "\n",
    "                predictions = self.model(imgs).view(32).float()\n",
    "                \n",
    "                loss = self.criterion(predictions, labels)\n",
    "                total_loss += loss.item() * len(imgs)\n",
    "\n",
    "                 # Calculate the accuracy\n",
    "                predictions = torch.argmax(predictions, dim=1)\n",
    "                correct += torch.sum(predictions == labels).item()\n",
    "\n",
    "        accuracy = correct / len(test_loader.dataset)\n",
    "        avg_loss = total_loss / len(test_loader.dataset)\n",
    "        return accuracy, avg_loss\n",
    "            \n",
    "\n",
    "def main():\n",
    "    save_model_every_n_epochs = config[\"save_model_every\"]\n",
    "    model = ViT(config)\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=config[\"lr\"], weight_decay=1e-2)\n",
    "    criterion = nn.MSELoss()\n",
    "    trainer = Trainer(model, optimizer, criterion, device=config[\"device\"])\n",
    "    trainer.train(train_loader, test_loader, config[\"num_epochs\"], save_model_every_n_epochs=save_model_every_n_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"TRAINING\"\"\"\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
