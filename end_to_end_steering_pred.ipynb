{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessed data already exists\n",
      "Not preprocessing, hopefully already done\n",
      "Preprocessed Dataset Length 45569\n",
      "Total Processing time : 0.02s\n"
     ]
    }
   ],
   "source": [
    "\"\"\"DATA PREPROCESSING\"\"\"\n",
    "\n",
    "from PIL import Image, ImageFilter, ImageEnhance, ImageFile\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "def crop(img):\n",
    "    width, height = img.size\n",
    "    img = img.crop((0, 130, width, height)) # try 120-150\n",
    "    return img\n",
    "\n",
    "\n",
    "def blur(img):\n",
    "    img = img.filter(ImageFilter.BLUR)\n",
    "    return img\n",
    "\n",
    "def darken(img):\n",
    "    enhancer = ImageEnhance.Brightness(img)\n",
    "    img = enhancer.enhance(0.5) # value proportional to brightness\n",
    "    return img\n",
    "\n",
    "def preprocess(data_path, save_dir, pre_process=False):\n",
    "    start = time.time()\n",
    "    if pre_process:\n",
    "        shutil.rmtree(save_dir, ignore_errors=True)\n",
    "        save_dir.mkdir(parents=True, exist_ok=True)\n",
    "        print(\"Save Dir created\")\n",
    "\n",
    "        for file in data_path.iterdir():\n",
    "            if str(file.suffix) == \".jpg\":\n",
    "                img = Image.open(data_path/file)\n",
    "                img = blur(img)\n",
    "                img = darken(img)\n",
    "                img = crop(img)\n",
    "\n",
    "                print(f\"Saving : {save_dir/file.name}\")\n",
    "                img.save(save_dir/file.name)\n",
    "\n",
    "            if str(file.stem)==\"data\":\n",
    "                shutil.copy(str(file),str(save_dir/file.name) )\n",
    "    else:\n",
    "        print(\"Not preprocessing, hopefully already done\")\n",
    "\n",
    "    print(\"Preprocessed Dataset Length\",len(os.listdir(save_dir)))\n",
    "    end = time.time()\n",
    "\n",
    "    print(f\"Total Processing time : {(end-start):.2f}s\")\n",
    "            \n",
    "\n",
    "def vis_image(img):\n",
    "    # plt.imshow(np.transpose(img,  (1, 2, 0)))\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "try:\n",
    "    from google.colab import drive\n",
    "    drive.mount(\"/content/drive\")\n",
    "\n",
    "    root_dir = Path(\"/content/drive/MyDrive/research\")\n",
    "    data_dir = Path(\"/content/data\")\n",
    "    data_path = data_dir/\"driving_dataset\"\n",
    "    save_dir = root_dir/\"driving_dataset_preprocessed\"\n",
    "    \n",
    "    DATA_DIR = save_dir\n",
    "    \n",
    "    EXP_DIR = root_dir/\"experiments\"\n",
    "  \n",
    "\n",
    "    !apt install unzip\n",
    "    if not DATA_DIR.exists():\n",
    "        !mkdir /content/data\n",
    "        !unzip /content/drive/MyDrive/research/driving_dataset.zip -d /content/data\n",
    "        preprocess(data_path=data_path, save_dir=DATA_DIR)\n",
    "    else:\n",
    "        print(\"Preprocessed data already exists\")\n",
    "    LABELS_PATH = DATA_DIR/\"data.txt\"\n",
    "except:\n",
    "    root_dir=Path(\"/home/avishkar/Desktop/research\")\n",
    "    data_path=root_dir/\"driving_dataset\"\n",
    "    save_dir=root_dir/\"driving_dataset_preprocessed\"\n",
    "    \n",
    "    DATA_DIR = save_dir\n",
    "    if not DATA_DIR.exists():\n",
    "        print(\"Dataset doesnt exist or not preprocessed\")\n",
    "        preprocess(data_path=data_path, save_dir=DATA_DIR, pre_process=True)\n",
    "    else:\n",
    "        print(\"Preprocessed data already exists\")\n",
    "    \n",
    "    LABELS_PATH = DATA_DIR/\"data.txt\"\n",
    "    EXP_DIR = root_dir/\"e2e_experiments\"\n",
    "\n",
    "preprocess(data_path=data_path, save_dir=save_dir)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not in colab\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: imageio in /home/avishkar/.local/lib/python3.10/site-packages (2.34.1)\n",
      "Requirement already satisfied: pillow>=8.3.2 in /home/avishkar/.local/lib/python3.10/site-packages (from imageio) (10.3.0)\n",
      "Requirement already satisfied: numpy in /home/avishkar/.local/lib/python3.10/site-packages (from imageio) (1.26.3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5714/1464081828.py:33: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
      "  img = iio.imread(self.data_dir/img_path)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"DATASET\"\"\"\n",
    "\n",
    "try:\n",
    "    from google.colab import drive\n",
    "    drive.mount(\"/content/drive\")\n",
    "    \n",
    "except:\n",
    "    print(\"not in colab\")\n",
    "        \n",
    "!pip install imageio\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from pathlib import Path\n",
    "import imageio as iio\n",
    "from torchvision.transforms import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "class DrivingDataset(Dataset):\n",
    "    def __init__(self, labels_path, data_dir, transform=None):\n",
    "        with open(Path(labels_path), \"r\") as f:\n",
    "            self.labels = f.readlines()\n",
    "            f.close()\n",
    "        self.data_dir = Path(data_dir)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def __getitem__(self, index) :\n",
    "        img_path, label = self.labels[index].split()\n",
    "        label=float(label)\n",
    "        img = iio.imread(self.data_dir/img_path)\n",
    "\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        return (img, label)\n",
    "        \n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Resize((32,32)),\n",
    "    # transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "])\n",
    "\n",
    "dataset = DrivingDataset(labels_path=LABELS_PATH, data_dir=DATA_DIR, transform=transform)\n",
    "# print(len(dataset))\n",
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = int(len(dataset)-train_size)\n",
    "train_set, test_set = random_split(dataset, [train_size, test_size])\n",
    "train_loader = DataLoader(train_set, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_set, batch_size=32, shuffle=False)\n",
    "\n",
    "for i, (imgs, labels) in enumerate(train_loader):\n",
    "    img = imgs[0]\n",
    "    label = labels[0]\n",
    "    plt.imshow(np.transpose(img,  (1, 2, 0)))\n",
    "    plt.title(f\"Steering angle: {label.item()}\")\n",
    "    # plt.axis('off')\n",
    "    plt.show()\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class PatchEmbeddings(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.img_size = config[\"img_size\"]\n",
    "        self.embed_dim = config[\"embed_dim\"]\n",
    "        self.patch_size = config[\"patch_size\"]\n",
    "        self.num_patches = (self.img_size // self.patch_size) **2\n",
    "        self.num_channels = config[\"num_channels\"]\n",
    "        self.patcher = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=self.num_channels,\n",
    "                out_channels=self.embed_dim,\n",
    "                kernel_size=self.patch_size,\n",
    "                stride=self.patch_size,\n",
    "            ),\n",
    "            nn.Flatten(2)\n",
    "        )\n",
    "        self.cls_token = nn.Parameter(\n",
    "            torch.randn(size=(1, 1,self.embed_dim)),\n",
    "            requires_grad=True\n",
    "            )\n",
    "        self.position_embeddings = nn.Parameter(\n",
    "            torch.randn(size=(1, self.num_patches+1, self.embed_dim)),\n",
    "            requires_grad=True\n",
    "            )\n",
    "        self.dropout = nn.Dropout(config[\"dropout\"])\n",
    "        \n",
    "    def forward(self, x):\n",
    "        cls_token = self.cls_token.expand(x.shape[0], -1, -1)\n",
    "        \n",
    "        x = self.patcher(x).permute(0, 2, 1)\n",
    "        x = torch.cat([cls_token,x ], dim=1)\n",
    "        x = self.position_embeddings + x\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "class ViT(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.embed_dim = config[\"embed_dim\"]\n",
    "        self.num_heads = config[\"num_heads\"]\n",
    "        self.num_classes = config[\"num_classes\"]\n",
    "        \n",
    "        self.embeddings = PatchEmbeddings(config)\n",
    "        self.encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=self.embed_dim,\n",
    "            nhead=self.num_heads,\n",
    "            dropout=config[\"dropout\"],\n",
    "            activation = \"gelu\",\n",
    "            batch_first=True,\n",
    "            norm_first=True\n",
    "        )\n",
    "        self.encoder_blocks = nn.TransformerEncoder(\n",
    "            self.encoder_layer,\n",
    "            num_layers = config[\"num_layers\"]\n",
    "        )\n",
    "\n",
    "        self.mlp_head = nn.Sequential(\n",
    "            nn.LayerNorm(self.embed_dim),\n",
    "            nn.Linear(self.embed_dim, 64)\n",
    "        )\n",
    "        self.angle_pred = nn.Linear(64, 1, bias=True)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.embeddings(x)\n",
    "        x = self.encoder_blocks(x)\n",
    "        x = self.mlp_head(x[:, 0, :]) # apply MLP on the CLS token only\n",
    "        x = self.angle_pred(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"UTILS\"\"\"\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "def save_checkpoint(state_dict, epoch, path):\n",
    "    p = Path(path)\n",
    "    if not p.exists():\n",
    "        print(\"Creating folder\")\n",
    "        p.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    model_details = {\n",
    "        \"epoch\":epoch,\n",
    "        \"state_dict\": state_dict,\n",
    "    }\n",
    "    torch.save(model_details, f\"{p}/vit_cifar10_{epoch}.pth\")\n",
    "    print(f\"model saved at path : {p}/vit_cifar10_{epoch}.pth\")\n",
    "\n",
    "\n",
    "def load_pretrained(model, path, epoch):\n",
    "    model.load_state_dict(torch.load(f\"{path}/vit_cifar10_{epoch}.pth\")[\"state_dict\"])\n",
    "    return model\n",
    "\n",
    "def save_experiment(model, epoch, config, train_losses, test_losses, train_accuracies,test_accuracies, path):\n",
    "    exp_data = {\n",
    "        \"train_losses\":train_losses,\n",
    "        \"test_losses\":test_losses,\n",
    "        \"train_accuracies\":train_accuracies,\n",
    "        \"test_accuracies\":test_accuracies,\n",
    "        \"epoch\":epoch,\n",
    "    }\n",
    "    exp_name = config[\"exp_name\"]\n",
    "    config_file = path/f\"{exp_name}\"/\"config.json\"\n",
    "    metrics_file = path/f\"{exp_name}\"/\"metrics.json\"\n",
    "    files = [config_file , metrics_file]\n",
    "    for file in files:\n",
    "        if file.exists():\n",
    "            print(f\"{file} exists\")\n",
    "        else:\n",
    "            file.parent.mkdir(parents=True, exist_ok=True)\n",
    "            file.touch()\n",
    "            print(f\"{file} created\")\n",
    "\n",
    "    with open(config_file, \"w\") as f:\n",
    "        json.dump(config, f, sort_keys=True, indent=4)\n",
    "    with open(metrics_file, \"w\") as f:\n",
    "        json.dump(exp_data, f, sort_keys=True, indent=4)\n",
    "\n",
    "    save_checkpoint(model.state_dict(), epoch, path/f\"{exp_name}\")\n",
    "\n",
    "def load_experiment(model ,exp_name, path):\n",
    "    with open(path/f\"{exp_name}\"/\"metrics.json\", 'r') as file:\n",
    "      data = json.load(file)\n",
    "    train_losses=data[\"train_losses\"]\n",
    "    test_losses=data[\"test_losses\"]\n",
    "    train_accuracies=data[\"train_accuracies\"]\n",
    "    test_accuracies=data[\"test_accuracies\"]\n",
    "    epoch=data[\"epoch\"]\n",
    "\n",
    "    model = load_pretrained(model, path/exp_name, epoch)\n",
    "\n",
    "    return model, train_losses, test_losses, train_accuracies,test_accuracies, epoch\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "config ={\n",
    "        \"img_size\":32,\n",
    "        \"embed_dim\":16*3, # (PATCH_SIZE ** 2) * IN_CHANNELS\n",
    "        \"patch_size\":4,\n",
    "        \"dropout\":0.0,\n",
    "        \"num_channels\":3,\n",
    "        \"num_heads\":4,\n",
    "        \"num_layers\":8,\n",
    "        \"num_classes\":10,\n",
    "        \"device\": \"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "        \"exp_name\":\"vit_mnist_40_epoch\",\n",
    "        \"num_epoch\":40\n",
    "    }\n",
    "\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "class Trainer:\n",
    "    def __init__(self, model, criterion, optimizer, device):\n",
    "        self.model = model.to(device)\n",
    "        self.criterion = criterion\n",
    "        self.optimizer = optimizer\n",
    "        self.device = device\n",
    "\n",
    "    def train(self, train_loader, test_loader, num_epochs):\n",
    "        train_losses, test_losses, train_accuracies, test_accuracies = [], [] , [], []\n",
    "        start = time.time()\n",
    "        for epoch in range(num_epochs):\n",
    "            ep_start = time.time()\n",
    "            train_loss, train_accuracy = self.train_epoch(train_loader)\n",
    "            test_loss, test_accuracy = self.evaluate(test_loader)\n",
    "            train_losses.append(train_loss)\n",
    "            test_losses.append(test_loss)\n",
    "            train_accuracies.append(train_accuracy)\n",
    "            test_accuracies.append(test_accuracy)\n",
    "\n",
    "            ep_end = time.time()\n",
    "            print(f\"Epoch: {epoch}/{num_epochs}, Time : {(ep_end-ep_start):.2f}s\")\n",
    "            print(f\"Train Loss: {train_loss:.4f}, Test Loss: {test_loss:.4f}\")\n",
    "            print(f\"Train Accuracy : {train_accuracy:.4f}, Test Accuracy: {test_accuracy:.4f}\")\n",
    "            \n",
    "        save_experiment(self.model, num_epochs, config, train_losses, test_losses, train_accuracies,test_accuracies, EXP_DIR)\n",
    "        end = time.time()\n",
    "        print(f\"Total Training Time : {(end-start):.2f}s\")\n",
    "            \n",
    "    def train_epoch(self, train_loader):\n",
    "        self.model.train()\n",
    "        correct = 0\n",
    "        running_train_loss = 0\n",
    "        for i, (imgs, labels) in enumerate(tqdm(train_loader, position=0, leave=True)):\n",
    "            imgs = imgs.float().to(self.device)\n",
    "            labels = labels.float().to(self.device)\n",
    "\n",
    "            predictions = self.model(imgs)\n",
    "            loss = self.criterion(predictions, labels)\n",
    "            running_train_loss += loss.item() * len(imgs)\n",
    "\n",
    "            self.optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "\n",
    "            predictions = torch.argmax(predictions, dim=1)\n",
    "            correct += torch.sum(predictions == labels).item()\n",
    "\n",
    "        accuracy = correct / len(train_loader.dataset)\n",
    "        train_loss = running_train_loss / len(train_loader.dataset)\n",
    "        return train_loss, accuracy\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def evaluate(self, test_loader):\n",
    "        self.model.eval()\n",
    "        correct = 0\n",
    "        running_test_loss = 0\n",
    "        for i, (imgs, labels) in enumerate(tqdm(test_loader, position=0, leave=True)):\n",
    "            imgs = imgs.to(self.device)\n",
    "            labels = labels.type(torch.uint8).to(self.device)\n",
    "\n",
    "            predictions = self.model(imgs)\n",
    "            loss = self.criterion(predictions, labels)\n",
    "            running_test_loss += loss.item() * len(imgs)\n",
    "\n",
    "            predictions = torch.argmax(predictions, dim=1)\n",
    "            correct += torch.sum(predictions == labels).item()\n",
    "\n",
    "        accuracy = correct / len(test_loader.dataset)\n",
    "        test_loss = running_test_loss / len(test_loader.dataset)\n",
    "        return test_loss, accuracy\n",
    "            \n",
    "def main():\n",
    "    model = ViT(config)\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "    trainer = Trainer(model, criterion, optimizer, config[\"device\"])\n",
    "    trainer.train(train_loader, test_loader, config[\"num_epoch\"])\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                        | 0/1136 [00:00<?, ?it/s]/tmp/ipykernel_5714/1464081828.py:33: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
      "  img = iio.imread(self.data_dir/img_path)\n",
      "  1%|▌                                              | 15/1136 [00:03<04:24,  4.24it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[49], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"TRAINING\"\"\"\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[48], line 94\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     92\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdam(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m)\n\u001b[1;32m     93\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(model, criterion, optimizer, config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdevice\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m---> 94\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnum_epoch\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[48], line 30\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, train_loader, test_loader, num_epochs)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[1;32m     29\u001b[0m     ep_start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m---> 30\u001b[0m     train_loss, train_accuracy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m     test_loss, test_accuracy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevaluate(test_loader)\n\u001b[1;32m     32\u001b[0m     train_losses\u001b[38;5;241m.\u001b[39mappend(train_loss)\n",
      "Cell \u001b[0;32mIn[48], line 50\u001b[0m, in \u001b[0;36mTrainer.train_epoch\u001b[0;34m(self, train_loader)\u001b[0m\n\u001b[1;32m     48\u001b[0m correct \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     49\u001b[0m running_train_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m---> 50\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, (imgs, labels) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(tqdm(train_loader, position\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, leave\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)):\n\u001b[1;32m     51\u001b[0m     imgs \u001b[38;5;241m=\u001b[39m imgs\u001b[38;5;241m.\u001b[39mfloat()\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m     52\u001b[0m     labels \u001b[38;5;241m=\u001b[39m labels\u001b[38;5;241m.\u001b[39mfloat()\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tqdm/std.py:1181\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1178\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1180\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1181\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[1;32m   1182\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[1;32m   1183\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1184\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:675\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    673\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    674\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 675\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    676\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    677\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__getitems__\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__:\n\u001b[0;32m---> 49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__getitems__\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpossibly_batched_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/data/dataset.py:419\u001b[0m, in \u001b[0;36mSubset.__getitems__\u001b[0;34m(self, indices)\u001b[0m\n\u001b[1;32m    417\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices])  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[1;32m    418\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 419\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[idx]] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices]\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/data/dataset.py:419\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    417\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices])  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[1;32m    418\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 419\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindices\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices]\n",
      "Cell \u001b[0;32mIn[24], line 33\u001b[0m, in \u001b[0;36mDrivingDataset.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     31\u001b[0m img_path, label \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabels[index]\u001b[38;5;241m.\u001b[39msplit()\n\u001b[1;32m     32\u001b[0m label\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mfloat\u001b[39m(label)\n\u001b[0;32m---> 33\u001b[0m img \u001b[38;5;241m=\u001b[39m \u001b[43miio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata_dir\u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43mimg_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform:\n\u001b[1;32m     36\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform(img)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/imageio/__init__.py:97\u001b[0m, in \u001b[0;36mimread\u001b[0;34m(uri, format, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"imread(uri, format=None, **kwargs)\u001b[39;00m\n\u001b[1;32m     69\u001b[0m \n\u001b[1;32m     70\u001b[0m \u001b[38;5;124;03mReads an image from the specified file. Returns a numpy array, which\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;124;03m    to see what arguments are available for a particular format.\u001b[39;00m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     89\u001b[0m warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m     90\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStarting with ImageIO v3 the behavior of this function will switch to that of\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     91\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m iio.v3.imread. To keep the current behavior (and make this warning disappear)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     94\u001b[0m     stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m     95\u001b[0m )\n\u001b[0;32m---> 97\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimread_v2\u001b[49m\u001b[43m(\u001b[49m\u001b[43muri\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/imageio/v2.py:360\u001b[0m, in \u001b[0;36mimread\u001b[0;34m(uri, format, **kwargs)\u001b[0m\n\u001b[1;32m    357\u001b[0m imopen_args[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlegacy_mode\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    359\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m imopen(uri, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mri\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mimopen_args) \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[0;32m--> 360\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfile\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    362\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/imageio/plugins/pillow.py:252\u001b[0m, in \u001b[0;36mPillowPlugin.read\u001b[0;34m(self, index, mode, rotate, apply_gamma, writeable_output, pilmode, exifrotate, as_gray)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(index, \u001b[38;5;28mint\u001b[39m):\n\u001b[1;32m    250\u001b[0m     \u001b[38;5;66;03m# will raise IO error if index >= number of frames in image\u001b[39;00m\n\u001b[1;32m    251\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_image\u001b[38;5;241m.\u001b[39mseek(index)\n\u001b[0;32m--> 252\u001b[0m     image \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply_transforms\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_image\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrotate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mapply_gamma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwriteable_output\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    256\u001b[0m     iterator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miter(\n\u001b[1;32m    257\u001b[0m         mode\u001b[38;5;241m=\u001b[39mmode,\n\u001b[1;32m    258\u001b[0m         rotate\u001b[38;5;241m=\u001b[39mrotate,\n\u001b[1;32m    259\u001b[0m         apply_gamma\u001b[38;5;241m=\u001b[39mapply_gamma,\n\u001b[1;32m    260\u001b[0m         writeable_output\u001b[38;5;241m=\u001b[39mwriteable_output,\n\u001b[1;32m    261\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/imageio/plugins/pillow.py:335\u001b[0m, in \u001b[0;36mPillowPlugin._apply_transforms\u001b[0;34m(self, image, mode, rotate, apply_gamma, writeable_output)\u001b[0m\n\u001b[1;32m    331\u001b[0m         image \u001b[38;5;241m=\u001b[39m image\u001b[38;5;241m.\u001b[39mconvert(desired_mode)\n\u001b[1;32m    333\u001b[0m image \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(image)\n\u001b[0;32m--> 335\u001b[0m meta \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_image\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtell\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexclude_applied\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    336\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m rotate \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOrientation\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m meta:\n\u001b[1;32m    337\u001b[0m     transformation \u001b[38;5;241m=\u001b[39m _exif_orientation_transform(\n\u001b[1;32m    338\u001b[0m         meta[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOrientation\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_image\u001b[38;5;241m.\u001b[39mmode\n\u001b[1;32m    339\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/imageio/plugins/pillow.py:537\u001b[0m, in \u001b[0;36mPillowPlugin.metadata\u001b[0;34m(self, index, exclude_applied)\u001b[0m\n\u001b[1;32m    534\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_image\u001b[38;5;241m.\u001b[39mmode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mP\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m exclude_applied:\n\u001b[1;32m    535\u001b[0m     metadata[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpalette\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(\u001b[38;5;28mtuple\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_image\u001b[38;5;241m.\u001b[39mpalette\u001b[38;5;241m.\u001b[39mcolors\u001b[38;5;241m.\u001b[39mkeys()))\n\u001b[0;32m--> 537\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_image\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetexif\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    538\u001b[0m     exif_data \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    539\u001b[0m         ExifTags\u001b[38;5;241m.\u001b[39mTAGS\u001b[38;5;241m.\u001b[39mget(key, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munknown\u001b[39m\u001b[38;5;124m\"\u001b[39m): value\n\u001b[1;32m    540\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mdict\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_image\u001b[38;5;241m.\u001b[39mgetexif())\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m    541\u001b[0m     }\n\u001b[1;32m    542\u001b[0m     exif_data\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munknown\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/PIL/Image.py:1468\u001b[0m, in \u001b[0;36mImage.getexif\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1465\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exif\u001b[38;5;241m.\u001b[39mload(exif_info)\n\u001b[1;32m   1467\u001b[0m \u001b[38;5;66;03m# XMP tags\u001b[39;00m\n\u001b[0;32m-> 1468\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mExifTags\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mBase\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mOrientation\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_exif\u001b[49m:\n\u001b[1;32m   1469\u001b[0m     xmp_tags \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minfo\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mXML:com.adobe.xmp\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1470\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m xmp_tags:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/PIL/Image.py:3965\u001b[0m, in \u001b[0;36mExif.__contains__\u001b[0;34m(self, tag)\u001b[0m\n\u001b[1;32m   3962\u001b[0m         \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info[tag]\n\u001b[1;32m   3963\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data[tag]\n\u001b[0;32m-> 3965\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__contains__\u001b[39m(\u001b[38;5;28mself\u001b[39m, tag) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n\u001b[1;32m   3966\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tag \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data \u001b[38;5;129;01mor\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m tag \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info)\n\u001b[1;32m   3968\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__setitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, tag, value) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\"\"\"TRAINING\"\"\"\n",
    "\n",
    "main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"\"\"Visualize Losses\"\"\"\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "model = ViT(config)\n",
    "_, train_losses, test_losses, train_accuracies, test_accuracies,_ = load_experiment(model, config[\"exp_name\"], EXPERIMENT_DIR)\n",
    "# Create two subplots of train/test losses and accuracies\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "ax1.plot(train_losses, label=\"Train loss\")\n",
    "ax1.plot(test_losses, label=\"Test loss\")\n",
    "ax1.set_xlabel(\"Epoch\")\n",
    "ax1.set_ylabel(\"Loss\")\n",
    "ax1.legend()\n",
    "ax2.plot(train_accuracies, label=\"Training Accuracy\")\n",
    "ax2.plot(test_accuracies, label=\"Test accuracy\")\n",
    "ax2.set_xlabel(\"Epoch\")\n",
    "ax2.set_ylabel(\"Accuracy\")\n",
    "plt.savefig(\"metrics.png\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
